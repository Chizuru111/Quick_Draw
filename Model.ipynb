{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading quickdraw libraries**"
      ],
      "metadata": {
        "id": "k4xx0hWSSRUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install quickdraw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLJdXx4qSPkE",
        "outputId": "ec9fbfee-bac9-40fb-edfa-b04bd2d10444"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: quickdraw in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from quickdraw) (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from quickdraw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->quickdraw) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import libraries**"
      ],
      "metadata": {
        "id": "J35bG4BbKblx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdop1vGmSsIZ",
        "outputId": "0e8a1159-843a-43e6-db6e-a721ba6c99ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from quickdraw import QuickDrawDataGroup\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8p7E1neyKaST"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change the device to GPU**"
      ],
      "metadata": {
        "id": "ktDEEjb1KjpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch._C import device\n",
        "# # Get cpu or gpu device (if available) for training.\n",
        "# if torch.cuda.is_available():\n",
        "#   device = torch.device(\"cuda\")\n",
        "# print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "6Sw7c-a92dJ8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import glob\n",
        "\n",
        "# directory_path = '/content/Dataset'\n",
        "# file_paths = glob.glob(directory_path + '/*.npy')\n",
        "\n",
        "# # Check the shape of each file\n",
        "# for file_path in file_paths:\n",
        "#     with open(file_path, 'rb') as f:\n",
        "#         data = np.load(f, allow_pickle=True)\n",
        "#         print(f\"{file_path}: {data.shape}\")\n"
      ],
      "metadata": {
        "id": "tNo85ew25ndb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creat"
      ],
      "metadata": {
        "id": "30BjBbe3MDq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the categories**"
      ],
      "metadata": {
        "id": "-Y0aiWlyKxKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = (\"bat\", \"bee\", \"cat\", \"duck\", \"elephant\", \"lion\", \"octopus\", \"rabbit\", \"snail\", \"whale\")\n",
        "image_size = (64, 64)\n",
        "max_drawings = 3000"
      ],
      "metadata": {
        "id": "4NDhxi0nLNnv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the doodles**"
      ],
      "metadata": {
        "id": "LFo_o1NfLcy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (64, 64)\n",
        "categories = [\"airplane\", \"apple\", \"bicycle\", \"car\", \"cat\", \"cloud\", \"dog\", \"hamburger\", \"fish\", \"flower\", \"banana\", \"bird\", \"eye\", \"fork\", \"hat\"]\n",
        "max_drawings = 5000\n",
        "\n",
        "def generate_class_images(name, max_drawings, recognized):\n",
        "    directory = Path(\"data/\" + name)\n",
        "\n",
        "    if not directory.exists():\n",
        "        directory.mkdir(parents=True)\n",
        "\n",
        "    images = QuickDrawDataGroup(name, max_drawings=max_drawings, recognized=recognized)\n",
        "    for img in images.drawings:\n",
        "        filename = directory.as_posix() + \"/\" + str(img.key_id) + \".png\"\n",
        "        img.get_image(stroke_width=3).resize(image_size).save(filename)\n",
        "\n",
        "for label in categories:\n",
        "    generate_class_images(label, max_drawings=max_drawings, recognized=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTdT7HC6LZzS",
        "outputId": "100bfca8-6a16-4875-898e-90450a47c63a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading airplane drawings\n",
            "load complete\n",
            "loading apple drawings\n",
            "load complete\n",
            "loading bicycle drawings\n",
            "load complete\n",
            "loading car drawings\n",
            "load complete\n",
            "loading cat drawings\n",
            "load complete\n",
            "loading cloud drawings\n",
            "load complete\n",
            "loading dog drawings\n",
            "load complete\n",
            "loading hamburger drawings\n",
            "load complete\n",
            "loading fish drawings\n",
            "load complete\n",
            "loading flower drawings\n",
            "load complete\n",
            "loading banana drawings\n",
            "load complete\n",
            "loading bird drawings\n",
            "load complete\n",
            "loading eye drawings\n",
            "load complete\n",
            "loading fork drawings\n",
            "load complete\n",
            "loading hat drawings\n",
            "load complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining dataset**"
      ],
      "metadata": {
        "id": "p52o8vHSMsgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdC32U8RMzJg",
        "outputId": "b78518cb-a780-4a31-fb5d-8138185cb75e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 75000 files belonging to 15 classes.\n",
            "Using 60000 files for training.\n",
            "Found 75000 files belonging to 15 classes.\n",
            "Using 15000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch.utils.data import DataLoader\n",
        "# import torchvision\n",
        "# from torchvision import datasets\n",
        "\n",
        "# batch_size = 64\n",
        "\n",
        "# # Create data loaders.\n",
        "# train_dataloader = DataLoader(X_train, batch_size=batch_size)\n",
        "# test_dataloader = DataLoader(X_test, batch_size=batch_size)\n",
        "\n",
        "# # for X, y in test_dataloader:\n",
        "# #     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "# #     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "# #     break"
      ],
      "metadata": {
        "id": "jpEld-Vz1RPm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the model**"
      ],
      "metadata": {
        "id": "NNMOVqaRHUUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# def softmax(x):\n",
        "#   return torch.exp(x) / torch.sum(torch.exp(x), dim=0)\n",
        "\n",
        "# loss_fn = tf.keras.metrics.categorical_crossentropy\n",
        "# lr = 5e-1\n",
        "# optm = SGD(learning_rate=lr)"
      ],
      "metadata": {
        "id": "dQ0cIE6m6g-5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "num_classes = 10  # Set this to the number of categories you have\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Rescaling(1. / 255, input_shape=(64, 64, 1)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(6, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(8, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(10, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(700, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(500, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(400, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(len(categories), activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "Jd_fCuAKyNsm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compiling the model**"
      ],
      "metadata": {
        "id": "lzWmFA-XHzUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TRNoCRS2Ht1f",
        "outputId": "c7034a88-4b95-4c1a-f6ef-f15c5e8c5fe8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f014070029e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_3.compile(optimizer='adam',\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the model**"
      ],
      "metadata": {
        "id": "uAmWY6u1IXXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 32\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data = validation_dataset,\n",
        "    epochs = epochs\n",
        ")\n",
        "\n",
        "model.save(\"./models/test_model\")"
      ],
      "metadata": {
        "id": "DCKCsxhNIW_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(dataloader, model, loss_fn, optimizer):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     # count the correct predictions\n",
        "#     correct = 0\n",
        "#     # when training, we put the model in train mode\n",
        "#     model.train()\n",
        "#     # we iterate over the dataloader\n",
        "#     for batch, (X, y) in enumerate(dataloader):\n",
        "#         # in each iteration, we work with a batch of 64 images\n",
        "#         # we move to GPU first if GPU is available\n",
        "#         X, y = X.to(device), y.to(device)\n",
        "\n",
        "#         # step1: forward pass\n",
        "#         ### Your code here (1 line) ###\n",
        "#         pred = model(X)\n",
        "\n",
        "#         ######################\n",
        "\n",
        "#         # step2: compute prediction error/loss\n",
        "#         ### Your code here (1 line) ###\n",
        "#         loss = loss_fn(pred, y)\n",
        "#         ######################\n",
        "\n",
        "#         # counting the correct predictions\n",
        "#         correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "#         # step 3: Backpropagation & parameter updating\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "#         ######################\n",
        "\n",
        "#         # step 4: zero the accumulated gradients in the tensors (1 lines)\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "\n",
        "#         ######################\n",
        "\n",
        "\n",
        "#         # every 100 batches, we print out the loss information to get an idea of\n",
        "#         # how good we are\n",
        "#         if batch % 100 == 0:\n",
        "#             loss, current = loss.item(), (batch + 1) * len(X)\n",
        "#             print(f\"Running loss for a batch of 100 images: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "#     correct /= size\n",
        "#     print(f\"Training accuracy for this epoch: {(100*correct):>0.1f}%\")"
      ],
      "metadata": {
        "id": "Wa6_YCnS2QyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 30\n",
        "# batch_size = 64\n",
        "# model.fit(train_dataloader,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#           validation_data=test_dataloader)"
      ],
      "metadata": {
        "id": "Cl4UUdeDyXFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing accuracy**"
      ],
      "metadata": {
        "id": "daonDlfJIpNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(validation_dataset, verbose=2)"
      ],
      "metadata": {
        "id": "HbwD7Hr8I5lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input a random image**"
      ],
      "metadata": {
        "id": "JKpRw0MnJQNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "  data = images[0].numpy().astype(\"uint8\")\n",
        "  plt.imshow(data, cmap='gray', vmin=0, vmax=255)\n",
        "  plt.title(train_dataset.class_names[labels[0]])\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "9V6aBUCBJL6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a prediction**"
      ],
      "metadata": {
        "id": "OAJTpvM9JuB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_data = train_dataset.take(1)\n",
        "for images, labels in prediction_data:\n",
        "  data = images[0].numpy().astype(\"uint8\")\n",
        "  plt.imshow(data, cmap='gray', vmin=0, vmax=255)\n",
        "  plt.title(train_dataset.class_names[labels[0]])\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "\n",
        "predictions = model_3.predict(prediction_data)\n",
        "categories[np.argmax(predictions[0])]"
      ],
      "metadata": {
        "id": "TGsUd6F4J1aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test(dataloader, model, loss_fn):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     num_batches = len(dataloader)\n",
        "#     # when evaluating, we put the model in evaluation mode\n",
        "#     model.eval()\n",
        "#     test_loss, correct = 0, 0\n",
        "#     # when evaluating, we disable gradient accumulations\n",
        "#     with torch.no_grad():\n",
        "#         for X, y in dataloader:\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             pred = model(X)\n",
        "#             test_loss += loss_fn(pred, y).item()\n",
        "#             # this compute the accuracy\n",
        "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "#     test_loss /= num_batches\n",
        "#     correct /= size\n",
        "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "3Hetu2ie37nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "# print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "AGRIC4jMyaJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "# # save the state_dict to the path \"model.pth\"\n",
        "# # TODO\n",
        "# print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "id": "NLa8z27g4Frw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "id": "f_b4PR8Z4V0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}